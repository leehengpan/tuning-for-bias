{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9b8f63",
   "metadata": {},
   "source": [
    "### Import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454d5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import json\n",
    "from preprocess import *\n",
    "from prepare import *\n",
    "from transformer import TransformerModel\n",
    "from lossacc import masked_loss, masked_accuracy\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24291515",
   "metadata": {},
   "source": [
    "### Prepare Fox News and NYT data for modeling\n",
    "\n",
    "1. Clean text\n",
    "2. Collate data files\n",
    "3. Build maps (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bac0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 16385 articles in file ../data/foxnews_content.json\n",
      "Processed 10560 articles in file ../data/nyt_content.json\n",
      "Saved to ../data/nytfox_collate.json\n"
     ]
    }
   ],
   "source": [
    "input_files = ['../data/foxnews_content.json', '../data/nyt_content.json']\n",
    "collate_file = '../data/nytfox_collate.json'\n",
    "\n",
    "clean_text = [remove_char_encoding, remove_special_char, make_lowercase]\n",
    "collate_data(input_files, save_to=collate_file, clean_text=clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fec70e",
   "metadata": {},
   "source": [
    "### Preprocess collated data\n",
    "\n",
    "1. Build train-test split\n",
    "2. Tokenize and vectorize train and test splits\n",
    "3. Intialize embeddings based on glove 100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aea63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:26:00.625956: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25184, 256) (25184, 16) (1325, 256) (1325, 16)\n",
      "Unique words in glove: 400003\n",
      "Hits: 14315; Misses: 685\n",
      "Hits: 68712; Misses: 21651\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2470)\n",
    "train_content, train_title, test_content, test_title = train_test_split(collate_file)\n",
    "(content_vocab, content_word_index, content_index_word, \n",
    " title_vocab, title_word_index, title_index_word) = vectorize_data(train_content, train_title)\n",
    "\n",
    "train_content_vec = CONTENT_VECTORIZER(train_content)\n",
    "train_title_vec = TITLE_VECTORIZER(train_title)\n",
    "test_content_vec = CONTENT_VECTORIZER(test_content)\n",
    "test_title_vec = TITLE_VECTORIZER(test_title)\n",
    "\n",
    "print(train_content_vec.shape, train_title_vec.shape, test_content_vec.shape, test_title_vec.shape)\n",
    "\n",
    "glove_index = build_glove_embed_index()\n",
    "title_embedding_init, title_vocab_size = build_embedding_init(title_word_index, glove_index)\n",
    "content_embedding_init, content_vocab_size = build_embedding_init(content_word_index, glove_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17989128",
   "metadata": {},
   "source": [
    "### Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d3236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "embedding_size = GLOVE_EMBED_SZ\n",
    "content_window_size = CONTENT_SEQ_LEN\n",
    "title_window_size = TITLE_SEQ_LEN\n",
    "content_embedding_initializer = tf.keras.initializers.Constant(content_embedding_init)\n",
    "title_embedding_initializer = tf.keras.initializers.Constant(title_embedding_init)\n",
    "content_embedding_trainability = True\n",
    "title_embedding_trainability = True\n",
    "dropout_rate = 0.1\n",
    "\n",
    "train_title_labels = train_title_vec[:,:,tf.newaxis]\n",
    "test_title_labels = test_title_vec[:,:,tf.newaxis]\n",
    "\n",
    "model = TransformerModel(num_layers, num_heads, ff_dim, embedding_size, content_vocab_size, title_vocab_size,\n",
    "                         content_window_size, title_window_size, content_embedding_initializer, title_embedding_initializer,\n",
    "                         content_embedding_trainability, title_embedding_trainability, dropout_rate)\n",
    "\n",
    "model_name = 'modelv2-2blocks-8heads-256ffdim-trainableemb-15ep'\n",
    "model.compile(optimizer='Adam', loss=masked_loss, metrics=[masked_accuracy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec1277",
   "metadata": {},
   "source": [
    "### Train\n",
    "(optional- use only if training new model; either to change architecture or update model weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdeedca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=(train_content_vec, train_title_vec[:,:-1]), y=train_title_labels[:,1:], \n",
    "#           batch_size=20, epochs=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a8a87",
   "metadata": {},
   "source": [
    "#### Save model weights\n",
    "\n",
    "(optional- use only if new model weights need to be saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46317321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = f'../weights/{model_name}'\n",
    "\n",
    "def save_model_weights(filepath):\n",
    "    if os.path.isfile(f'{filepath}.index'):\n",
    "        confirmation = input('File exists; hit y to override: ')\n",
    "        \n",
    "        if confirmation.lower()=='y':\n",
    "            model.save_weights(filepath)\n",
    "        else:\n",
    "            print('Not saving; try saving with different filename')\n",
    "    else:\n",
    "        model.save_weights(filepath)\n",
    "\n",
    "# save_model_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2066c",
   "metadata": {},
   "source": [
    "#### Load model weights \n",
    "(optional- use only if testing custom model with different weights and same architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fff9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2cbe7f010>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_path = f'../weights/{model_name}'\n",
    "model.load_weights(f'{model_weights_path}') \n",
    "\n",
    "## e.g. model.load_weights('../models/weights/modelv2-2blocks-5heads-256ffdim-trainableemb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfc5d8",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aeeeb2",
   "metadata": {},
   "source": [
    "#### Setup functions for use in inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480d77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_ind(indexes, index_word_dict=title_index_word):\n",
    "    \"\"\"Convenience function with no generalization- converts index to word from user defined dictionary\"\"\"\n",
    "    sentence = \"\"\n",
    "    for index in indexes:\n",
    "        sentence += index_word_dict[index]\n",
    "        sentence += \" \"\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def reverse_bias(content):\n",
    "    \"\"\"Convenience function with no generalization- just a hack to reverse the bias\"\"\"\n",
    "    words = content.split()\n",
    "    view = words[1]\n",
    "    \n",
    "    if view=='liberal':\n",
    "        words[1] = 'conservative'\n",
    "    else:\n",
    "        words[1] = 'liberal'\n",
    "    reverse_bias_content = ' '.join(words)\n",
    "    return reverse_bias_content, view, words[1]\n",
    "\n",
    "\n",
    "def text_to_title(content, model=model, output_len=TITLE_SEQ_LEN, \n",
    "                  start_token=START_TOKEN, end_token=END_TOKEN):\n",
    "    \"\"\"Converts vectorized text to title\n",
    "    Arguments:\n",
    "        content - vectorized text\"\"\"\n",
    "    \n",
    "    start, end = (tf.constant(title_word_index[start_token], dtype=tf.int64), \n",
    "                  tf.constant(title_word_index[end_token], dtype=tf.int64))\n",
    "    \n",
    "    start = start[tf.newaxis]\n",
    "    end = end[tf.newaxis]\n",
    "    \n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(output_len):\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        predictions = model([content[tf.newaxis], output], training=False)\n",
    "        \n",
    "        # Select the last token from the `seq_len` dimension.\n",
    "        predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "        predicted_id = tf.argmax(predictions, axis=2)\n",
    "\n",
    "        # Concatenate the `predicted_id` to the output which is given to the\n",
    "        # decoder as its input.\n",
    "        output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "        \n",
    "    output = output_array.stack().numpy().reshape(1,-1)\n",
    "    predicted_title = sentence_from_ind(output[0].tolist())\n",
    "    return predicted_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba36d60",
   "metadata": {},
   "source": [
    "#### Reverse bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562432d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse bias of test file articles to gauge bias in titles; \n",
    "# titles are then compared for each political view for the same set of articles\n",
    "\n",
    "test_reverse_content = []\n",
    "test_original_view = []\n",
    "test_reverse_view = []\n",
    "\n",
    "for content in test_content:\n",
    "    reverse_bias_content, original_view, reverse_view = reverse_bias(content)\n",
    "    \n",
    "    test_reverse_content.append(reverse_bias_content)\n",
    "    test_original_view.append(original_view)\n",
    "    test_reverse_view.append(reverse_view)\n",
    "    \n",
    "test_reverse_content_vec = CONTENT_VECTORIZER(test_reverse_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b832d",
   "metadata": {},
   "source": [
    "#### Run inference \n",
    "\n",
    "Content conditioned on original labels (i.e. as per source Fox => 'conservative' vs. NYT => 'liberal'), and reversed labels (i.e. opposite to original source Fox => 'liberal' vs. NYT => 'conservative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b1c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed inference on 100 articles\n",
      "Completed inference on 200 articles\n",
      "Completed inference on 300 articles\n",
      "Completed inference on 400 articles\n",
      "Completed inference on 500 articles\n",
      "Completed inference on 600 articles\n",
      "Completed inference on 700 articles\n",
      "Completed inference on 800 articles\n"
     ]
    }
   ],
   "source": [
    "true_titles = []\n",
    "predicted_titles_original_bias = []\n",
    "predicted_titles_reverse_bias = []\n",
    "bleu_score_original_bias = []\n",
    "bleu_score_reverse_bias = []\n",
    "\n",
    "test_articles_len = len(test_content)\n",
    "\n",
    "for index in range(test_articles_len):\n",
    "    content_vec, reverse_content_vec, true_title = test_content_vec[index], test_reverse_content_vec[index], test_title[index]\n",
    "    predicted_title_original_bias = text_to_title(content_vec)\n",
    "    predicted_title_reverse_bias = text_to_title(reverse_content_vec)\n",
    "    \n",
    "    true_titles.append(true_title)\n",
    "    predicted_titles_original_bias.append(predicted_title_original_bias)\n",
    "    predicted_titles_reverse_bias.append(predicted_title_reverse_bias)\n",
    "    \n",
    "    bleu_score_original_bias.append(sentence_bleu([true_title.split()], predicted_title_original_bias.split(), \n",
    "                                    weights=(1,0,0,0)))\n",
    "    bleu_score_reverse_bias.append(sentence_bleu([true_title.split()], predicted_title_reverse_bias.split(), \n",
    "                                    weights=(1,0,0,0)))\n",
    "    if (index+1)%100==0:\n",
    "        print(f'Completed inference on {index+1} articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41695770",
   "metadata": {},
   "source": [
    "#### Save results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = f'../results/{model_name}-results.csv'\n",
    "df = pd.DataFrame(data=[true_titles, predicted_titles_original_bias, predicted_titles_reverse_bias,\n",
    "                        bleu_score_original_bias, bleu_score_reverse_bias,\n",
    "                        test_original_view[:test_articles_len], test_reverse_view[:test_articles_len]]).T\n",
    "df.columns = ['true_title','predicted_title_original_bias', 'predicted_title_reverse_bias',\n",
    "              'bleu_score_original_bias', 'bleu_score_reverse_bias',\n",
    "              'original_view', 'reverse_view']\n",
    "df['mean_bleu_score'] = (df['bleu_score_original_bias']+df['bleu_score_reverse_bias'])/2\n",
    "df.sort_values(by=['mean_bleu_score'],ascending=[False],inplace=True)\n",
    "df.to_csv(results_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
