{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeae3681",
   "metadata": {},
   "source": [
    "### Import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cab0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import json\n",
    "from preprocess import *\n",
    "from prepare import *\n",
    "from transformer import TransformerModel\n",
    "from lossacc import masked_loss, masked_accuracy\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee7834",
   "metadata": {},
   "source": [
    "### Prepare Fox News and NYT data for modeling\n",
    "\n",
    "1. Clean text\n",
    "2. Collate data files\n",
    "3. Build maps (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82749750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 16385 articles in file ../data/foxnews_content.json\n",
      "Processed 10560 articles in file ../data/nyt_content.json\n",
      "Saved to ../data/nytfox_collate.json\n"
     ]
    }
   ],
   "source": [
    "input_files = ['../data/foxnews_content.json', '../data/nyt_content.json']\n",
    "collate_file = '../data/nytfox_collate.json'\n",
    "\n",
    "clean_text = [remove_char_encoding, remove_special_char, make_lowercase]\n",
    "collate_data(input_files, save_to=collate_file, clean_text=clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aba671",
   "metadata": {},
   "source": [
    "### Preprocess collated data\n",
    "\n",
    "1. Build train-test split\n",
    "2. Tokenize and vectorize train and test splits\n",
    "3. Intialize embeddings based on glove 100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aea63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 23:19:59.102114: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25184, 256) (25184, 16) (1325, 256) (1325, 16)\n",
      "Unique words in glove: 400003\n",
      "Hits: 14315; Misses: 685\n",
      "Hits: 68712; Misses: 21651\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2470)\n",
    "train_content, train_title, test_content, test_title = train_test_split(collate_file)\n",
    "(content_vocab, content_word_index, content_index_word, \n",
    " title_vocab, title_word_index, title_index_word) = vectorize_data(train_content, train_title)\n",
    "\n",
    "train_content_vec = CONTENT_VECTORIZER(train_content)\n",
    "train_title_vec = TITLE_VECTORIZER(train_title)\n",
    "test_content_vec = CONTENT_VECTORIZER(test_content)\n",
    "test_title_vec = TITLE_VECTORIZER(test_title)\n",
    "\n",
    "print(train_content_vec.shape, train_title_vec.shape, test_content_vec.shape, test_title_vec.shape)\n",
    "\n",
    "glove_index = build_glove_embed_index()\n",
    "title_embedding_init, title_vocab_size = build_embedding_init(title_word_index, glove_index)\n",
    "content_embedding_init, content_vocab_size = build_embedding_init(content_word_index, glove_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43830d",
   "metadata": {},
   "source": [
    "### Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d3236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metrics=[masked_accuracy]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "embedding_size = GLOVE_EMBED_SZ\n",
    "content_window_size = CONTENT_SEQ_LEN\n",
    "title_window_size = TITLE_SEQ_LEN\n",
    "content_embedding_initializer = tf.keras.initializers.Constant(content_embedding_init)\n",
    "title_embedding_initializer = tf.keras.initializers.Constant(title_embedding_init)\n",
    "content_embedding_trainability = True\n",
    "title_embedding_trainability = True\n",
    "dropout_rate = 0.1\n",
    "\n",
    "train_title_labels = train_title_vec[:,:,tf.newaxis]\n",
    "test_title_labels = test_title_vec[:,:,tf.newaxis]\n",
    "\n",
    "model = TransformerModel(num_layers, num_heads, ff_dim, embedding_size, content_vocab_size, title_vocab_size,\n",
    "                         content_window_size, title_window_size, content_embedding_initializer, title_embedding_initializer,\n",
    "                         content_embedding_trainability, title_embedding_trainability, dropout_rate)\n",
    "\n",
    "model_name = 'modelv2-2blocks-8heads-256ffdim-trainableemb-30ep'\n",
    "model.compile(optimizer='Adam', loss=masked_loss, metrics=[masked_accuracy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2dc62",
   "metadata": {},
   "source": [
    "### Train\n",
    "(optional- use only if training new model; either to change architecture or update model weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdeedca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 463s 4s/step - loss: 7.6169 - masked_accuracy: 0.0892\n",
      "Epoch 2/30\n",
      "126/126 [==============================] - 454s 4s/step - loss: 7.0226 - masked_accuracy: 0.1091\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 476s 4s/step - loss: 6.5739 - masked_accuracy: 0.1329\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 472s 4s/step - loss: 6.1733 - masked_accuracy: 0.1520\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 464s 4s/step - loss: 5.8207 - masked_accuracy: 0.1718\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 484s 4s/step - loss: 5.4957 - masked_accuracy: 0.1877\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 454s 4s/step - loss: 5.1982 - masked_accuracy: 0.2042\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 453s 4s/step - loss: 4.9369 - masked_accuracy: 0.2178\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 464s 4s/step - loss: 4.7156 - masked_accuracy: 0.2298\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 463s 4s/step - loss: 4.5131 - masked_accuracy: 0.2410\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 449s 4s/step - loss: 4.3229 - masked_accuracy: 0.2533\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 448s 4s/step - loss: 4.1393 - masked_accuracy: 0.2671\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 448s 4s/step - loss: 3.9716 - masked_accuracy: 0.2823\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 456s 4s/step - loss: 3.8165 - masked_accuracy: 0.2982\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 448s 4s/step - loss: 3.6692 - masked_accuracy: 0.3137\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 450s 4s/step - loss: 3.5309 - masked_accuracy: 0.3292\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 456s 4s/step - loss: 3.4108 - masked_accuracy: 0.3437\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 451s 4s/step - loss: 3.2907 - masked_accuracy: 0.3583\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 450s 4s/step - loss: 3.1884 - masked_accuracy: 0.3708\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 449s 4s/step - loss: 3.0830 - masked_accuracy: 0.3841\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 446s 4s/step - loss: 2.9831 - masked_accuracy: 0.3964\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 451s 4s/step - loss: 2.8934 - masked_accuracy: 0.4081\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 448s 4s/step - loss: 2.8070 - masked_accuracy: 0.4203\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 448s 4s/step - loss: 2.7253 - masked_accuracy: 0.4321\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 440s 3s/step - loss: 2.6508 - masked_accuracy: 0.4419\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 442s 4s/step - loss: 2.5744 - masked_accuracy: 0.4522\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 441s 4s/step - loss: 2.5041 - masked_accuracy: 0.4632\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 440s 3s/step - loss: 2.4390 - masked_accuracy: 0.4722\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 442s 4s/step - loss: 2.3763 - masked_accuracy: 0.4816\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 441s 3s/step - loss: 2.3160 - masked_accuracy: 0.4906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30a23bbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=(train_content_vec, train_title_vec[:,:-1]), y=train_title_labels[:,1:], \n",
    "          batch_size=200, epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9aaf25",
   "metadata": {},
   "source": [
    "#### Save model weights\n",
    "\n",
    "(optional- use only if new model weights need to be saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9240e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = f'../weights/{model_name}'\n",
    "\n",
    "def save_model_weights(filepath):\n",
    "    if os.path.isfile(f'{filepath}.index'):\n",
    "        confirmation = input('File exists; hit y to override: ')\n",
    "        \n",
    "        if confirmation.lower()=='y':\n",
    "            model.save_weights(filepath)\n",
    "        else:\n",
    "            print('Not saving; try saving with different filename')\n",
    "    else:\n",
    "        model.save_weights(filepath)\n",
    "\n",
    "# save_model_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16ceaf",
   "metadata": {},
   "source": [
    "#### Load model weights \n",
    "(optional- use only if testing custom model with different weights and same architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4daee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x30a30eec0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_weights_path = f'../weights/{model_name}'\n",
    "# model.load_weights(f'{model_weights_path}') \n",
    "\n",
    "## e.g. model.load_weights('../models/weights/modelv2-2blocks-5heads-256ffdim-trainableemb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e494f",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad6626",
   "metadata": {},
   "source": [
    "#### Setup functions for use in inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480d77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_ind(indexes, index_word_dict=title_index_word):\n",
    "    \"\"\"Convenience function with no generalization- converts index to word from user defined dictionary\"\"\"\n",
    "    sentence = \"\"\n",
    "    for index in indexes:\n",
    "        sentence += index_word_dict[index]\n",
    "        sentence += \" \"\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def reverse_bias(content):\n",
    "    \"\"\"Convenience function with no generalization- just a hack to reverse the bias\"\"\"\n",
    "    words = content.split()\n",
    "    view = words[1]\n",
    "    \n",
    "    if view=='liberal':\n",
    "        words[1] = 'conservative'\n",
    "    else:\n",
    "        words[1] = 'liberal'\n",
    "    reverse_bias_content = ' '.join(words)\n",
    "    return reverse_bias_content, view, words[1]\n",
    "\n",
    "\n",
    "def text_to_title(content, model=model, output_len=TITLE_SEQ_LEN, \n",
    "                  start_token=START_TOKEN, end_token=END_TOKEN):\n",
    "    \"\"\"Converts vectorized text to title\n",
    "    Arguments:\n",
    "        content - vectorized text\"\"\"\n",
    "    \n",
    "    start, end = (tf.constant(title_word_index[start_token], dtype=tf.int64), \n",
    "                  tf.constant(title_word_index[end_token], dtype=tf.int64))\n",
    "    \n",
    "    start = start[tf.newaxis]\n",
    "    end = end[tf.newaxis]\n",
    "    \n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(output_len):\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        predictions = model([content[tf.newaxis], output], training=False)\n",
    "        \n",
    "        # Select the last token from the `seq_len` dimension.\n",
    "        predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "        predicted_id = tf.argmax(predictions, axis=2)\n",
    "\n",
    "        # Concatenate the `predicted_id` to the output which is given to the\n",
    "        # decoder as its input.\n",
    "        output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "        \n",
    "    output = output_array.stack().numpy().reshape(1,-1)\n",
    "    predicted_title = sentence_from_ind(output[0].tolist())\n",
    "    return predicted_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bc803",
   "metadata": {},
   "source": [
    "#### Reverse bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562432d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse bias of test file articles to gauge bias in titles; \n",
    "# titles are then compared for each political view for the same set of articles\n",
    "\n",
    "test_reverse_content = []\n",
    "test_original_view = []\n",
    "test_reverse_view = []\n",
    "\n",
    "for content in test_content:\n",
    "    reverse_bias_content, original_view, reverse_view = reverse_bias(content)\n",
    "    \n",
    "    test_reverse_content.append(reverse_bias_content)\n",
    "    test_original_view.append(original_view)\n",
    "    test_reverse_view.append(reverse_view)\n",
    "    \n",
    "test_reverse_content_vec = CONTENT_VECTORIZER(test_reverse_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef84dda",
   "metadata": {},
   "source": [
    "#### Run inference \n",
    "\n",
    "Content conditioned on original labels (i.e. as per source Fox => 'conservative' vs. NYT => 'liberal'), and reversed labels (i.e. opposite to original source Fox => 'liberal' vs. NYT => 'conservative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48b1c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed inference on 100 articles\n",
      "Completed inference on 200 articles\n",
      "Completed inference on 300 articles\n",
      "Completed inference on 400 articles\n",
      "Completed inference on 500 articles\n",
      "Completed inference on 600 articles\n",
      "Completed inference on 700 articles\n",
      "Completed inference on 800 articles\n",
      "Completed inference on 900 articles\n",
      "Completed inference on 1000 articles\n",
      "Completed inference on 1100 articles\n",
      "Completed inference on 1200 articles\n",
      "Completed inference on 1300 articles\n"
     ]
    }
   ],
   "source": [
    "# true_titles = []\n",
    "# predicted_titles_original_bias = []\n",
    "# predicted_titles_reverse_bias = []\n",
    "# bleu_score_original_bias = []\n",
    "# bleu_score_reverse_bias = []\n",
    "\n",
    "# test_articles_len = len(test_content)\n",
    "\n",
    "# for index in range(test_articles_len):\n",
    "#     content_vec, reverse_content_vec, true_title = test_content_vec[index], test_reverse_content_vec[index], test_title[index]\n",
    "#     predicted_title_original_bias = text_to_title(content_vec)\n",
    "#     predicted_title_reverse_bias = text_to_title(reverse_content_vec)\n",
    "    \n",
    "#     true_titles.append(true_title)\n",
    "#     predicted_titles_original_bias.append(predicted_title_original_bias)\n",
    "#     predicted_titles_reverse_bias.append(predicted_title_reverse_bias)\n",
    "    \n",
    "#     bleu_score_original_bias.append(sentence_bleu([true_title.split()], predicted_title_original_bias.split(), \n",
    "#                                     weights=(1,0,0,0)))\n",
    "#     bleu_score_reverse_bias.append(sentence_bleu([true_title.split()], predicted_title_reverse_bias.split(), \n",
    "#                                     weights=(1,0,0,0)))\n",
    "#     if (index+1)%100==0:\n",
    "#         print(f'Completed inference on {index+1} articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1014e",
   "metadata": {},
   "source": [
    "#### Save results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7f7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_path = f'../results/{model_name}-results.csv'\n",
    "# df = pd.DataFrame(data=[true_titles, predicted_titles_original_bias, predicted_titles_reverse_bias,\n",
    "#                         bleu_score_original_bias, bleu_score_reverse_bias,\n",
    "#                         test_original_view[:test_articles_len], test_reverse_view[:test_articles_len]]).T\n",
    "# df.columns = ['true_title','predicted_title_original_bias', 'predicted_title_reverse_bias',\n",
    "#               'bleu_score_original_bias', 'bleu_score_reverse_bias',\n",
    "#               'original_view', 'reverse_view']\n",
    "# df['mean_bleu_score'] = (df['bleu_score_original_bias']+df['bleu_score_reverse_bias'])/2\n",
    "# df.sort_values(by=['mean_bleu_score'],ascending=[False],inplace=True)\n",
    "# df.to_csv(results_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39442233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1325, 256), dtype=int64, numpy=\n",
       " array([[  23,   40,   25, ...,  249,    8,   24],\n",
       "        [  23,   40,   25, ...,    2,  296,   24],\n",
       "        [  23,   40,   25, ..., 3651, 2442,   24],\n",
       "        ...,\n",
       "        [  23,   63,   25, ...,  703,    2,   24],\n",
       "        [  23,   40,   25, ..., 4662,  115,   24],\n",
       "        [  23,   40,   25, ...,    2,   65,   24]])>,\n",
       " <tf.Tensor: shape=(1325, 15), dtype=int64, numpy=\n",
       " array([[    2,    14,   166, ...,    11, 10573,     3],\n",
       "        [    2,  1842,   314, ...,   289,    44,   109],\n",
       "        [    2,    16,  2976, ...,   622,     3,     0],\n",
       "        ...,\n",
       "        [    2,  2857,    22, ...,     0,     0,     0],\n",
       "        [    2,    94,  1402, ...,    94,   949,    10],\n",
       "        [    2,   889,   960, ...,  2681,  1918,     3]])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_content_vec, test_title_vec[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451cf242",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'masked_loss/mul' defined at (most recent call last):\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/hz/mq1t9krj4kv9cxjz4g5c_p8c0000gn/T/ipykernel_23006/1782201265.py\", line 5, in <module>\n      model.evaluate(x=[test_content_vec, test_title_vec[:,:-1]],y=test_title_vec[:,1:],verbose=2)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1758, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/losses.py\", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/sagarraichandani/Documents/Brown/Academic/csci2470/project/text-to-title/src/lossacc.py\", line 9, in masked_loss\n      loss *= mask\nNode: 'masked_loss/mul'\nIncompatible shapes: [32,15] vs. [32,15,1]\n\t [[{{node masked_loss/mul}}]] [Op:__inference_test_function_15914]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.fit(x=(train_content_vec, train_title_vec[:,:-1]), y=train_title_labels[:,1:], \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#           batch_size=20, epochs=15)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtest_content_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_title_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_title_vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'masked_loss/mul' defined at (most recent call last):\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/hz/mq1t9krj4kv9cxjz4g5c_p8c0000gn/T/ipykernel_23006/1782201265.py\", line 5, in <module>\n      model.evaluate(x=[test_content_vec, test_title_vec[:,:-1]],y=test_title_vec[:,1:],verbose=2)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1758, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/csci2470-project/lib/python3.10/site-packages/keras/losses.py\", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/sagarraichandani/Documents/Brown/Academic/csci2470/project/text-to-title/src/lossacc.py\", line 9, in masked_loss\n      loss *= mask\nNode: 'masked_loss/mul'\nIncompatible shapes: [32,15] vs. [32,15,1]\n\t [[{{node masked_loss/mul}}]] [Op:__inference_test_function_15914]"
     ]
    }
   ],
   "source": [
    "# model.fit(x=(train_content_vec, train_title_vec[:,:-1]), y=train_title_labels[:,1:], \n",
    "#           batch_size=20, epochs=15)\n",
    "\n",
    "\n",
    "model.evaluate(x=[test_content_vec, test_title_vec[:,:-1]],y=test_title_vec[:,1:],verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_vec.shape[1]==test_title_vec.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef6e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
