{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformer import TransformerModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2929c14b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initalize model\n",
    "model = TransformerModel(emb_sz=100, num_heads=5, key_dim=64, vocab_size=15000)\n",
    "\n",
    "# compile model with Adam optimizer and masked loss and masked accuracy \n",
    "model.compile(optimizer='Adam', loss=TransformerModel.masked_loss, metrics=[TransformerModel.masked_accuracy])\n",
    "\n",
    "# load weights\n",
    "model.load_weights('../models/weights/2blocks-fixedlr-datav2_75epochs_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train content data from pickle \n",
    "with open('../data/embeddings/train_content_embeddings.pkl','rb') as f:\n",
    "    train_content_emb = pickle.load(f)\n",
    "\n",
    "# get train title data from pickle \n",
    "with open('../data/embeddings/train_title_embeddings.pkl','rb') as f:\n",
    "    train_title_emb = pickle.load(f)\n",
    "\n",
    "# get train title labels data from pickle \n",
    "with open('../data/embeddings/train_title_labels.pkl','rb') as f:\n",
    "    train_title_tokens = pickle.load(f)\n",
    "\n",
    "# get test content data from pickle \n",
    "with open('../data/embeddings/test_content_embeddings.pkl','rb') as f:\n",
    "    test_content_emb = pickle.load(f)\n",
    "    \n",
    "# get test title data from pickle \n",
    "with open('../data/embeddings/test_title_embeddings.pkl','rb') as f:\n",
    "    test_title_emb = pickle.load(f)\n",
    "    \n",
    "# get test title labels data from pickle \n",
    "with open('../data/embeddings/test_title_labels.pkl','rb') as f:\n",
    "    test_title_tokens = pickle.load(f)\n",
    "\n",
    "# get word dictionary data from pickle \n",
    "with open('../data/embeddings/title_index_word.pkl','rb') as f:\n",
    "    word_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert indexes to words using defined dict \n",
    "def sentence_from_ind(indexes):\n",
    "    sentence = \"\"\n",
    "    \n",
    "    for index in indexes:\n",
    "   \n",
    "        sentence += word_dict[index]\n",
    "        sentence += \" \"\n",
    "    \n",
    "    return sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for training and testing \n",
    "train_content_data = tf.convert_to_tensor(train_content_emb)\n",
    "train_title_data = tf.convert_to_tensor(train_title_emb)\n",
    "train_title_labels = tf.convert_to_tensor(train_title_tokens)\n",
    "\n",
    "test_content_data = tf.convert_to_tensor(test_content_emb)\n",
    "test_title_data = tf.convert_to_tensor(test_title_emb)\n",
    "test_title_labels = tf.convert_to_tensor(test_title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 138ms/step\n",
      "16/16 [==============================] - 2s 146ms/step\n"
     ]
    }
   ],
   "source": [
    "# create predictions \n",
    "pred_train = model.predict((train_content_data[:500], train_title_data[:500]))\n",
    "pred_test = model.predict((test_content_data[:500], test_title_data[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>oliver blocked chinas weibo website clamps dow...</td>\n",
       "      <td>john oliver blocked chinas weibo website clamp...</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>lessons american who designed the modern sneak...</td>\n",
       "      <td>meet the american who designed the modern snea...</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>ag ag ripped for gop challenger claim frivolou...</td>\n",
       "      <td>democrat minnesota ag ripped by gop challenger...</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>paul staffer suffered deep knife wound to head...</td>\n",
       "      <td>rand paul staffer suffered deep knife wound to...</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>weingartens is wsj retort on schools schools e...</td>\n",
       "      <td>randi weingartens [UNK] wsj retort on schools ...</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>is government doctors the is government your i...</td>\n",
       "      <td>what are [UNK] rights</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>agency education for heads decision bill im to...</td>\n",
       "      <td>a public health victory</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>important the record a houses team we learning...</td>\n",
       "      <td>education</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>education paris american of russias a small a ...</td>\n",
       "      <td>[UNK] meets the world</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nuclear is built plan power murky is to to lot...</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             predicted  \\\n",
       "139  oliver blocked chinas weibo website clamps dow...   \n",
       "184  lessons american who designed the modern sneak...   \n",
       "322  ag ag ripped for gop challenger claim frivolou...   \n",
       "261  paul staffer suffered deep knife wound to head...   \n",
       "385  weingartens is wsj retort on schools schools e...   \n",
       "..                                                 ...   \n",
       "209  is government doctors the is government your i...   \n",
       "47   agency education for heads decision bill im to...   \n",
       "2    important the record a houses team we learning...   \n",
       "181  education paris american of russias a small a ...   \n",
       "34   nuclear is built plan power murky is to to lot...   \n",
       "\n",
       "                                                  true    BLEU  \n",
       "139  john oliver blocked chinas weibo website clamp...  0.8125  \n",
       "184  meet the american who designed the modern snea...  0.8125  \n",
       "322  democrat minnesota ag ripped by gop challenger...  0.7500  \n",
       "261  rand paul staffer suffered deep knife wound to...  0.7500  \n",
       "385  randi weingartens [UNK] wsj retort on schools ...  0.7500  \n",
       "..                                                 ...     ...  \n",
       "209                 what are [UNK] rights               0.0000  \n",
       "47                a public health victory               0.0000  \n",
       "2                            education                  0.0000  \n",
       "181                 [UNK] meets the world               0.0000  \n",
       "34                         environment                  0.0000  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save training results to csv\n",
    "predicted_sent_list = []\n",
    "true_sent_list = []\n",
    "BLEU_scores = []\n",
    "\n",
    "for i in range(0, 500):\n",
    "    tokens = np.argmax(pred_train[i],axis=1)\n",
    "    true = train_title_labels[i].numpy().reshape((16,))\n",
    "\n",
    "    pred_sent = sentence_from_ind(tokens)\n",
    "    true_sent = sentence_from_ind(true)\n",
    "\n",
    "    predicted_sent_list.append(pred_sent)\n",
    "    true_sent_list.append(true_sent)\n",
    "    BLEU_scores.append(sentence_bleu([true_sent.split()],pred_sent.split(), weights=(1, 0, 0, 0)))\n",
    "\n",
    "df_train = pd.DataFrame({'predicted':predicted_sent_list, 'true':true_sent_list, 'BLEU':BLEU_scores})\n",
    "df_train = df_train.sort_values(by='BLEU', ascending=False)\n",
    "# df_train.to_csv('../results/train_results.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>scott ceo elon ceo his his on social praise on...</td>\n",
       "      <td>rumble ceo tells tucker carlson his company is...</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>19 to to covid 5 5 for thursday covid before v...</td>\n",
       "      <td>de blasio to pay kids 100 to get the covid 19 ...</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>south covid covid johnson reported reported jo...</td>\n",
       "      <td>johnson johnson covid vaccine linked to death ...</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>mask pan to mask masks mask for public transit...</td>\n",
       "      <td>new york continues to enforce mask mandate for...</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>department to to aid to on 31 31 drone by atta...</td>\n",
       "      <td>us state department proposes [UNK] sale of [UN...</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>press controversial globe progress sparks on e...</td>\n",
       "      <td>brazil [UNK] all its votes in hours it still f...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>claims breaking ukraines russian ukraine of co...</td>\n",
       "      <td>russias claim to seize a ukrainian town expose...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>protests lefts dire join conference to regimes...</td>\n",
       "      <td>cop26 protesters in glasgow push for action fr...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>kudlow greta should climate dies kerry based h...</td>\n",
       "      <td>abby [UNK] challenges jane fonda on [UNK] gree...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>mayor mayor charged charged 4 crush access lin...</td>\n",
       "      <td>former atlanta councilman sentenced for lying ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             predicted  \\\n",
       "314  scott ceo elon ceo his his on social praise on...   \n",
       "351  19 to to covid 5 5 for thursday covid before v...   \n",
       "485  south covid covid johnson reported reported jo...   \n",
       "377  mask pan to mask masks mask for public transit...   \n",
       "444  department to to aid to on 31 31 drone by atta...   \n",
       "..                                                 ...   \n",
       "402  press controversial globe progress sparks on e...   \n",
       "334  claims breaking ukraines russian ukraine of co...   \n",
       "335  protests lefts dire join conference to regimes...   \n",
       "399  kudlow greta should climate dies kerry based h...   \n",
       "394  mayor mayor charged charged 4 crush access lin...   \n",
       "\n",
       "                                                  true    BLEU  \n",
       "314  rumble ceo tells tucker carlson his company is...  0.3750  \n",
       "351  de blasio to pay kids 100 to get the covid 19 ...  0.3125  \n",
       "485  johnson johnson covid vaccine linked to death ...  0.3125  \n",
       "377  new york continues to enforce mask mandate for...  0.3125  \n",
       "444  us state department proposes [UNK] sale of [UN...  0.3125  \n",
       "..                                                 ...     ...  \n",
       "402  brazil [UNK] all its votes in hours it still f...  0.0000  \n",
       "334  russias claim to seize a ukrainian town expose...  0.0000  \n",
       "335  cop26 protesters in glasgow push for action fr...  0.0000  \n",
       "399  abby [UNK] challenges jane fonda on [UNK] gree...  0.0000  \n",
       "394  former atlanta councilman sentenced for lying ...  0.0000  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save test predictions to csv\n",
    "predicted_sent_list = []\n",
    "true_sent_list = []\n",
    "BLEU_scores = []\n",
    "\n",
    "for i in range(0,500):\n",
    "    tokens = np.argmax(pred_test[i],axis=1)\n",
    "    true = test_title_labels[i].numpy().reshape((16,))\n",
    "\n",
    "    pred_sent = sentence_from_ind(tokens)\n",
    "    true_sent = sentence_from_ind(true)\n",
    "\n",
    "    predicted_sent_list.append(pred_sent)\n",
    "    true_sent_list.append(true_sent)\n",
    "    BLEU_scores.append(sentence_bleu([true_sent.split()],pred_sent.split(), weights=(1, 0, 0, 0)))\n",
    "\n",
    "df_test = pd.DataFrame({'predicted':predicted_sent_list, 'true':true_sent_list, 'BLEU':BLEU_scores})\n",
    "df_test = df_test.sort_values(by='BLEU', ascending=False)\n",
    "# df_test.to_csv('../results/test_results.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09025"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['BLEU'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
