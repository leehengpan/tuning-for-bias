{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897f5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import json\n",
    "from preprocess_v2 import *\n",
    "from nltk.translate.bleu_score import sentence_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aea63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 15:04:25.819332: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25184, 256) (25184, 16) (1325, 256) (1325, 16)\n",
      "Unique words in glove: 400003\n",
      "Hits: 14315; Misses: 685\n",
      "Hits: 68712; Misses: 21651\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2470)\n",
    "train_content, train_title, test_content, test_title = train_test_split()\n",
    "(content_vocab, content_word_index, content_index_word, \n",
    " title_vocab, title_word_index, title_index_word) = vectorize_data(train_content, train_title)\n",
    "\n",
    "train_content_vec = CONTENT_VECTORIZER(train_content)\n",
    "train_title_vec = TITLE_VECTORIZER(train_title)\n",
    "test_content_vec = CONTENT_VECTORIZER(test_content)\n",
    "test_title_vec = TITLE_VECTORIZER(test_title)\n",
    "\n",
    "print(train_content_vec.shape, train_title_vec.shape, test_content_vec.shape, test_title_vec.shape)\n",
    "\n",
    "glove_index = build_glove_embed_index()\n",
    "title_embedding_init, title_vocab_size = build_embedding_init(title_word_index, glove_index)\n",
    "content_embedding_init, content_vocab_size = build_embedding_init(content_word_index, glove_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87ec5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_size, window_size, initializer, trainable=False):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.window_size = window_size\n",
    "        self.initializer = initializer\n",
    "        self.trainable = trainable\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_size, mask_zero=True,\n",
    "                                                   embeddings_initializer=self.initializer,\n",
    "                                                   trainable=self.trainable)    \n",
    "        self.positional_encoding = positional_encoding(window_size, embedding_size)\n",
    "    \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "        \n",
    "    def call(self, x, add_positional_embedding=True):\n",
    "        length = tf.shape(x)[1]\n",
    "        if add_positional_embedding:\n",
    "            return self.embedding(x)+positional_encoding(length, self.embedding_size)\n",
    "        else:\n",
    "            return self.embedding(x)\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output = self.mha(query=x, key=context, value=context)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x, attention_mask=None):\n",
    "        attn_output = self.mha(query=x, value=x, key=x, attention_mask=attention_mask)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x, attention_mask=None):\n",
    "        attn_output = self.mha(query=x, value=x, key=x, use_causal_mask=True, attention_mask=attention_mask)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_size, ff_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([tf.keras.layers.Dense(ff_dim, activation='relu'),\n",
    "                                        tf.keras.layers.Dense(embedding_size),\n",
    "                                        tf.keras.layers.Dropout(dropout_rate)])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b341557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, embedding_size, ff_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_size = embedding_size\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.self_attention = GlobalSelfAttention(num_heads=num_heads, key_dim=embedding_size,\n",
    "                                                  dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(embedding_size, ff_dim)\n",
    "\n",
    "    def call(self, x, attention_mask=None):\n",
    "        x = self.self_attention(x, attention_mask=attention_mask)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, num_heads, ff_dim, vocab_size, embedding_size, \n",
    "                 window_size, embedding_initializer, embedding_trainability=False,  dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.window_size = window_size\n",
    "        self.embedding_initializer = embedding_initializer\n",
    "        self.embedding_trainability = embedding_trainability\n",
    "        \n",
    "        self.pos_embedding = PositionalEmbedding(self.vocab_size, self.embedding_size, self.window_size,\n",
    "                                                 self.embedding_initializer, self.embedding_trainability)\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(num_heads, embedding_size, ff_dim, dropout_rate) for i in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # x is tokenized numerical values\n",
    "        mask = self.pos_embedding.compute_mask(x)\n",
    "        mask = mask[:,tf.newaxis,:]\n",
    "        x = self.pos_embedding(x)\n",
    "        \n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, attention_mask=mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4934f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, embedding_size, ff_dim, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(num_heads=num_heads, key_dim=embedding_size, \n",
    "                                                         dropout=dropout_rate)\n",
    "        self.cross_attention = CrossAttention(num_heads=num_heads, key_dim=embedding_size, \n",
    "                                              dropout=dropout_rate)\n",
    "        self.ffn = FeedForward(embedding_size, ff_dim)\n",
    "\n",
    "    def call(self, x, context, attention_mask=None):\n",
    "        x = self.causal_self_attention(x=x, attention_mask=attention_mask)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, num_heads, ff_dim, vocab_size, embedding_size, window_size,\n",
    "                 embedding_initializer, embedding_trainability=False, dropout_rate=0.1):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        self.embedding_initializer = embedding_initializer\n",
    "        self.embedding_trainability = embedding_trainability\n",
    "\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(self.vocab_size, self.embedding_size, self.window_size,\n",
    "                                                 self.embedding_initializer, self.embedding_trainability)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(num_heads, embedding_size, ff_dim,  dropout_rate=dropout_rate) \n",
    "                           for i in range(num_layers)]\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "        mask = self.pos_embedding.compute_mask(x)\n",
    "        mask = mask[:,tf.newaxis,:]\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context, attention_mask=mask)\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b46ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, num_layers, num_heads, ff_dim, embedding_size, \n",
    "                 content_vocab_size, title_vocab_size, content_window_size, title_window_size,\n",
    "                 content_embedding_initializer, title_embedding_initializer,\n",
    "                 content_embedding_trainability, title_embedding_trainability, \n",
    "                 dropout_rate=0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, num_heads, ff_dim, content_vocab_size, embedding_size, \n",
    "                               content_window_size, content_embedding_initializer, content_embedding_trainability,\n",
    "                               dropout_rate)\n",
    "        self.decoder = Decoder(num_layers, num_heads, ff_dim, title_vocab_size, embedding_size,\n",
    "                               title_window_size, title_embedding_initializer, title_embedding_trainability,\n",
    "                               dropout_rate)\n",
    "        \n",
    "        self.dense_layer = tf.keras.layers.Dense(title_vocab_size)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        content, title = inputs        \n",
    "        context = self.encoder(content)\n",
    "        output = self.decoder(title, context)\n",
    "        logits = self.dense_layer(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d3236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "embedding_size = GLOVE_EMBED_SZ\n",
    "content_window_size = CONTENT_SEQ_LEN\n",
    "title_window_size = TITLE_SEQ_LEN\n",
    "content_embedding_initializer = tf.keras.initializers.Constant(content_embedding_init)\n",
    "title_embedding_initializer = tf.keras.initializers.Constant(title_embedding_init)\n",
    "content_embedding_trainability = True\n",
    "title_embedding_trainability = True\n",
    "dropout_rate = 0.1\n",
    "\n",
    "train_title_labels = train_title_vec[:,:,tf.newaxis]\n",
    "test_title_labels = test_title_vec[:,:,tf.newaxis]\n",
    "\n",
    "model = TransformerModel(num_layers, num_heads, ff_dim, embedding_size, content_vocab_size, title_vocab_size,\n",
    "                         content_window_size, title_window_size, content_embedding_initializer, title_embedding_initializer,\n",
    "                         content_embedding_trainability, title_embedding_trainability, dropout_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdeedca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 469s 4s/step - loss: 7.5409 - masked_accuracy: 0.0961\n",
      "Epoch 2/30\n",
      "126/126 [==============================] - 474s 4s/step - loss: 6.7160 - masked_accuracy: 0.1264\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 458s 4s/step - loss: 6.1684 - masked_accuracy: 0.1545\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 464s 4s/step - loss: 5.7388 - masked_accuracy: 0.1772\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 462s 4s/step - loss: 5.4109 - masked_accuracy: 0.1942\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 475s 4s/step - loss: 5.1327 - masked_accuracy: 0.2090\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 471s 4s/step - loss: 4.8788 - masked_accuracy: 0.2229\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 463s 4s/step - loss: 4.6509 - masked_accuracy: 0.2362\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 550s 4s/step - loss: 4.4444 - masked_accuracy: 0.2490\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 630s 5s/step - loss: 4.2488 - masked_accuracy: 0.2622\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 570s 5s/step - loss: 4.0720 - masked_accuracy: 0.2743\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 597s 5s/step - loss: 3.8984 - masked_accuracy: 0.2907\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 680s 5s/step - loss: 3.7394 - masked_accuracy: 0.3072\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 686s 5s/step - loss: 3.5933 - masked_accuracy: 0.3228\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 449s 4s/step - loss: 3.4556 - masked_accuracy: 0.3376\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 452s 4s/step - loss: 3.3270 - masked_accuracy: 0.3538\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 456s 4s/step - loss: 3.2073 - masked_accuracy: 0.3694\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 452s 4s/step - loss: 3.0921 - masked_accuracy: 0.3839\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 454s 4s/step - loss: 2.9840 - masked_accuracy: 0.3984\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 464s 4s/step - loss: 2.8856 - masked_accuracy: 0.4110\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 449s 4s/step - loss: 2.7961 - masked_accuracy: 0.4234\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 451s 4s/step - loss: 2.7035 - masked_accuracy: 0.4360\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 459s 4s/step - loss: 2.6203 - masked_accuracy: 0.4476\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 453s 4s/step - loss: 2.5429 - masked_accuracy: 0.4587\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 451s 4s/step - loss: 2.4633 - masked_accuracy: 0.4698\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 452s 4s/step - loss: 2.3933 - masked_accuracy: 0.4801\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 452s 4s/step - loss: 2.3231 - masked_accuracy: 0.4906\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 446s 4s/step - loss: 2.2561 - masked_accuracy: 0.5016\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 446s 4s/step - loss: 2.1937 - masked_accuracy: 0.5107\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 446s 4s/step - loss: 2.1347 - masked_accuracy: 0.5184\n"
     ]
    }
   ],
   "source": [
    "model_name = 'modelv2-2blocks-8heads-256ffdim-trainableemb'\n",
    "\n",
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = tf.expand_dims(loss_object(label, pred),axis=2)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.expand_dims(tf.argmax(pred, axis=2), axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "model.compile(optimizer='Adam', loss=masked_loss, metrics=[masked_accuracy])\n",
    "\n",
    "model.fit(x=(train_content_vec, train_title_vec[:,:-1]), y=train_title_labels[:,1:], \n",
    "          batch_size=200, epochs=30)\n",
    "\n",
    "model_weights_path = f'../models/weights/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bea88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model_weights(filepath):\n",
    "    if os.path.isfile(filepath):\n",
    "        confirmation = input('File exists; hit y to override: ')\n",
    "        if confirmation.lower()=='y':\n",
    "            model.save_weights(filepath)\n",
    "        else:\n",
    "            print('Not saving; try saving with different filename')\n",
    "    else:\n",
    "        model.save_weights(filepath)\n",
    "\n",
    "save_model_weights(model_weights_path)\n",
    "\n",
    "# LOAD WEIGHTS USING:\n",
    "# model.load_weights('../models/weights/modelv2-2blocks-5heads-256ffdim-trainableemb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480d77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_ind(indexes, index_word_dict=title_index_word):\n",
    "    sentence = \"\"\n",
    "    \n",
    "    for index in indexes:\n",
    "   \n",
    "        sentence += index_word_dict[index]\n",
    "        sentence += \" \"\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "## NOT NECESSARY ANYMORE- DISCUSS AND REMOVE\n",
    "# predictions = model.predict(x=(test_content_vec[:100], test_title_vec[:100][:,:-1]))\n",
    "\n",
    "# for i in range(0,10):\n",
    "#     tokens = np.argmax(predictions[i],axis=1)\n",
    "#     true = test_title_labels[i].numpy().reshape((16,))\n",
    "#     count = 0\n",
    "#     for num in tokens:\n",
    "#         if num == 0:\n",
    "#             count +1\n",
    "\n",
    "#     # if count < 10:\n",
    "#     # print(tokens)\n",
    "#     print(f'Predicted Sentence {i}:',sentence_from_ind(tokens))\n",
    "#     print(f'True Sentence {i}:',sentence_from_ind(true))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562432d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def text_to_title(content, model=model, output_len=TITLE_SEQ_LEN):\n",
    "    \"\"\"Converts vectorized text to title\n",
    "    Arguments:\n",
    "        content - vectorized text\"\"\"\n",
    "    \n",
    "    start, end = tf.constant(title_word_index['<start>'], dtype=tf.int64), tf.constant(title_word_index['<end>'], dtype=tf.int64)\n",
    "    start = start[tf.newaxis]\n",
    "    end = end[tf.newaxis]\n",
    "    \n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(output_len):\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        predictions = model([content[tf.newaxis], output], training=False)\n",
    "        \n",
    "        # Select the last token from the `seq_len` dimension.\n",
    "        predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "        predicted_id = tf.argmax(predictions, axis=2)\n",
    "\n",
    "        # Concatenate the `predicted_id` to the output which is given to the\n",
    "        # decoder as its input.\n",
    "        output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "        \n",
    "    output = output_array.stack().numpy().reshape(1,-1)\n",
    "    predicted_title = sentence_from_ind(output[0].tolist())\n",
    "    return predicted_title\n",
    "\n",
    "true_titles = []\n",
    "predicted_titles = []\n",
    "BLEU_scores = []\n",
    "\n",
    "for index in range(200):\n",
    "    content_vec, true_title = test_content_vec[index], test_title[index]\n",
    "    predicted_title = text_to_title(content_vec)\n",
    "    true_titles.append(true_title)\n",
    "    predicted_titles.append(predicted_title)\n",
    "    BLEU_scores.append(sentence_bleu([true_title.split()], predicted_title.split(), weights=(1, 0, 0, 0)))\n",
    "    \n",
    "    if index%50==0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f03fcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[true_titles, predicted_titles, BLEU_scores]).T\n",
    "df.columns = ['true_title','predicted_title','BLEU_score']\n",
    "df.to_csv(f'../results/{model_name}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9da6f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses, dropout_2_layer_call_fn, dropout_2_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/modelv2-2blocks-8heads-256ffdim-trainableemb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/modelv2-2blocks-8heads-256ffdim-trainableemb/assets\n",
      "/Users/lihengpanza/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return serialization.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# model.save('../models/modelv2-2blocks-8heads-256ffdim-trainableemb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e0c168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  9785212   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  2894312   \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  1515000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,194,524\n",
      "Trainable params: 14,194,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_reload = tf.keras.models.load_model(\"../models/modelv2-2blocks-8heads-256ffdim-trainableemb\", custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy}) #\n",
    "# model_reload.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cdaa6d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'transformer_model' (type TransformerModel).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * [<tf.Tensor 'inputs:0' shape=(1, 256) dtype=int64>,\n <tf.Tensor 'inputs_1:0' shape=(1, 1) dtype=int64>]\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='inputs_0'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='inputs_1'))\n  Keyword arguments: {'training': False}\n\nOption 2:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='inputs_0'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='inputs_1'))\n  Keyword arguments: {'training': True}\n\nOption 3:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='input_1'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='input_2'))\n  Keyword arguments: {'training': False}\n\nOption 4:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='input_1'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='input_2'))\n  Keyword arguments: {'training': True}\n\nCall arguments received by layer 'transformer_model' (type TransformerModel):\n  • args=(['tf.Tensor(shape=(1, 256), dtype=int64)', 'tf.Tensor(shape=(1, 1), dtype=int64)'],)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m      6\u001b[0m     content_vec, true_title \u001b[39m=\u001b[39m test_content_vec[index], test_title[index]\n\u001b[0;32m----> 7\u001b[0m     predicted_title \u001b[39m=\u001b[39m text_to_title(content_vec,model\u001b[39m=\u001b[39;49mmodel_reload)\n\u001b[1;32m      8\u001b[0m     true_titles\u001b[39m.\u001b[39mappend(true_title)\n\u001b[1;32m      9\u001b[0m     predicted_titles\u001b[39m.\u001b[39mappend(predicted_title)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mtext_to_title\u001b[0;34m(content, model, output_len)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(output_len):\n\u001b[1;32m     16\u001b[0m     output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtranspose(output_array\u001b[39m.\u001b[39mstack())\n\u001b[0;32m---> 17\u001b[0m     predictions \u001b[39m=\u001b[39m model([content[tf\u001b[39m.\u001b[39;49mnewaxis], output], training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     19\u001b[0m     \u001b[39m# Select the last token from the `seq_len` dimension.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     predictions \u001b[39m=\u001b[39m predictions[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:, :]  \u001b[39m# Shape `(batch_size, 1, vocab_size)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/csci2470-project/lib/python3.10/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mOption \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  Keyword arguments: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSavedModel. Got:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00m_pretty_format_positional(args)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  Keyword \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marguments: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Expected these arguments to match one of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfollowing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(saved_function\u001b[39m.\u001b[39mconcrete_functions)\u001b[39m}\u001b[39;00m\u001b[39m option(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m(\u001b[39mchr\u001b[39m(\u001b[39m10\u001b[39m)\u001b[39m+\u001b[39m\u001b[39mchr\u001b[39m(\u001b[39m10\u001b[39m))\u001b[39m.\u001b[39mjoin(signature_descriptions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'transformer_model' (type TransformerModel).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * [<tf.Tensor 'inputs:0' shape=(1, 256) dtype=int64>,\n <tf.Tensor 'inputs_1:0' shape=(1, 1) dtype=int64>]\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='inputs_0'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='inputs_1'))\n  Keyword arguments: {'training': False}\n\nOption 2:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='inputs_0'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='inputs_1'))\n  Keyword arguments: {'training': True}\n\nOption 3:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='input_1'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='input_2'))\n  Keyword arguments: {'training': False}\n\nOption 4:\n  Positional arguments (1 total):\n    * (TensorSpec(shape=(None, 256), dtype=tf.int64, name='input_1'),\n TensorSpec(shape=(None, 15), dtype=tf.int64, name='input_2'))\n  Keyword arguments: {'training': True}\n\nCall arguments received by layer 'transformer_model' (type TransformerModel):\n  • args=(['tf.Tensor(shape=(1, 256), dtype=int64)', 'tf.Tensor(shape=(1, 1), dtype=int64)'],)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "true_titles = []\n",
    "predicted_titles = []\n",
    "BLEU_scores = []\n",
    "\n",
    "for index in range(10):\n",
    "    content_vec, true_title = test_content_vec[index], test_title[index]\n",
    "    predicted_title = text_to_title(content_vec,model=model_reload)\n",
    "    true_titles.append(true_title)\n",
    "    predicted_titles.append(predicted_title)\n",
    "    BLEU_scores.append(sentence_bleu([true_title.split()], predicted_title.split(), weights=(1, 0, 0, 0)))\n",
    "    \n",
    "    if index%50==0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e2a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
